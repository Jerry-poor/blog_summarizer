{
  "title": "Cohere on Hugging Face Inference Providers 🔥",
  "link": "https://huggingface.co/blog/inference-providers-cohere",
  "published": "2025-04-16",
  "summary": "**Abstract:**\n\nWe announce Cohere's integration as a supported Inference Provider on Hugging Face Hub.\n我们宣布 Cohere 已集成到 Hugging Face Hub 作为支持的推理提供商。\n\nThis marks the first model creator to directly share and serve models on the Hub.\n这标志着第一个模型创建者直接在 Hub 上共享和提供模型。\n\nCohere offers secure AI solutions for enterprise use, including Generative AI, Embeddings, and Ranking models.\nCohere 为企业用途提供安全的 AI 解决方案，包括生成式 AI、嵌入和排序模型。\n\nCohereLabs supports fundamental research and innovation.\nCohereLabs 支持基础研究和创新。\n\nUsers can now run serverless inference on models like *CohereLabs/c4ai-command-a-03-2025* and *CohereLabs/aya-expanse-32b*.\n用户现在可以在*CohereLabs/c4ai-command-a-03-2025*和*CohereLabs/aya-expanse-32b*等模型上运行无服务器推理。\n\n*CohereLabs/c4ai-command-a-03-2025* is optimized for enterprises needing fast, secure, high-quality AI with a 256k context length.\n*CohereLabs/c4ai-command-a-03-2025* 针对需要快速、安全、高质量 AI 且上下文长度为 256k 的企业进行了优化。\n\nLeverage Cohere and Cohere Labs for advanced AI applications.\n利用 Cohere 和 Cohere Labs 实现高级 AI 应用程序。\n\n**摘要 (Abstract)**\n\n本文介绍Cohere的先进检索增强生成 (RAG) 模型，具有可验证的引文、智能体工具使用、企业级安全性和强大的多语言性能（支持 23 种语言）。\nThis paper introduces Cohere's advanced retrieval-augmented generation (RAG) models with verifiable citations, agentic tool use, enterprise-grade security, and strong multilingual performance (support for 23 languages).\n\nCohereLabs/aya-expanse-32b 专注于最先进的多语言支持，应用了最新的多语言预训练研究。\nCohereLabs/aya-expanse-32b focuses on state-of-the-art multilingual support, applying the latest research on multilingual pre-training.\n\nCohereLabs/c4ai-command-r7b-12-2024 适用于低成本或低延迟用例，在同类开源模型中提供最先进的性能，并具有 128K 的上下文长度。\nCohereLabs/c4ai-command-r7b-12-2024 is ideal for low-cost or low-latency use cases, bringing state-of-the-art performance in its class of open-weight models, with a context length of 128K.\n\nCohereLabs/aya-vision-32b 是一个 320 亿参数模型，针对各种视觉-语言用例进行了优化，扩展了多模态功能至 23 种语言。\nCohereLabs/aya-vision-32b is a 32-billion parameter model optimized for vision-language use cases, expanding multimodal capabilities to 23 languages.\n\n可以通过 Hugging Face Hub 的网页 UI 或客户端 SDK 直接使用 Cohere 模型。\nCohere models can be directly used on the Hub either on the website UI or via the client SDKs.\n\n**Abstract:**\n\n本文介绍了如何使用 Hugging Face Hub 作为接口，调用 Cohere 的推理服务，包括文本生成和多模态处理。\nThis paper introduces how to utilize Hugging Face Hub as an interface to invoke Cohere's inference services, including text generation and multimodal processing.\n\n通过设置 `provider=\"cohere\"` 和 API 密钥，可以轻松地调用 Cohere 的端点。\nBy setting `provider=\"cohere\"` and the API key, Cohere's endpoints can be easily called.\n\n文本生成示例展示了如何使用 `InferenceClient` 和 `chat.completions.create()` 方法，使用如 \"CohereLabs/c4ai-command-r7b-12-2024\" 等模型进行对话。\nThe text generation example demonstrates how to use the `InferenceClient` and `chat.completions.create()` methods, using models like \"CohereLabs/c4ai-command-r7b-12-2024\" for dialogue.\n\n多模态处理示例则展示了如何通过 base64 编码嵌入图像，并使用 \"CohereLabs/aya-vision-32b\" 等模型进行图像理解，利用 `image_url = f\"data:image/jpeg;base64,{base64_image}\"` 传递图像数据。\nThe multimodal processing example demonstrates how to embed images via base64 encoding and utilize models such as \"CohereLabs/aya-vision-32b\" for image understanding, passing image data using `image_url = f\"data:image/jpeg;base64,{base64_image}\"`.\n\n**Abstract**\n\nThis work demonstrates calling Cohere's Command R7B model using the OpenAI client library via inference providers.\n本研究展示了如何通过Inference Providers使用OpenAI客户端库调用Cohere的Command R7B模型。\n\nThe implementation utilizes a custom base URL (e.g., `\"https://router.huggingface.co/cohere/compatibility/v1\"`) and API key for authentication.\n该实现使用自定义的 base URL (例如, `\"https://router.huggingface.co/cohere/compatibility/v1\"`) 和 API 密钥进行身份验证。\n\nFurthermore, we explore agentic tool use, defining a `get_flight_info` function with parameters for origin (`loc_origin`) and destination (`loc_destination`) airports.\n此外，我们探索了agentic工具的使用，定义了一个 `get_flight_info` 函数，其参数包括起始机场(`loc_origin`)和目标机场(`loc_destination`)。\n\nThe tool definition is then incorporated into the model's chat template, enabling the model to make appropriate `tool_calls` during inference.\n然后，工具定义被整合到模型的聊天模板中，使模型能够在推理过程中进行适当的 `tool_calls`。\n\n**Abstract:**\n\nThis work demonstrates the integration of a large language model (LLM) for flight information retrieval using the Hugging Face InferenceClient. This work utilizes a Cohere model `CohereLabs/c4ai-command-r7b-12-2024`.\n本文展示了使用Hugging Face InferenceClient集成大型语言模型(LLM)进行航班信息检索。This work utilizes a Cohere model `CohereLabs/c4ai-command-r7b-12-2024`.\n\nThe system processes a multi-turn conversation, including developer's date info, user's flight query (Miami to Seattle), and assistant's `tool_calls` using a function `get_flight_info` with arguments like `{ \"loc_destination\": \"Seattle\", \"loc_origin\": \"Miami\" }`.\n该系统处理多轮对话，包括开发人员的日期信息、用户的航班查询（迈阿密到西雅图）以及助手使用函数`get_flight_info`的`tool_calls`，参数如`{ \"loc_destination\": \"Seattle\", \"loc_origin\": \"Miami\" }`。\n\nThe tool provides the flight information, `Miami to Seattle, May 1st, 10 AM.`, which returns to the LLM.\n该工具提供了航班信息，`Miami to Seattle, May 1st, 10 AM.`，返回给LLM。\n\nBilling information is provided, emphasizing the standard Cohere API rates and potential Inference credits for PRO users.\n提供了账单信息，强调了标准的Cohere API费率和PRO用户的潜在Inference credits。\n\nThe paper also mentions related articles and community feedback.\n本文还提及了相关文章和社区反馈。\n\n**Abstract**\n\n本文讨论了用户对聊天记录API访问的需求，以便进行数据标注和用户行为研究。\nThis paper discusses the user demand for API access to chat logs for data labeling and user behavior research.\n\n目前，该功能尚未实现，但已被开发者考虑。\nCurrently, this functionality is not implemented but is under consideration by the developers.\n\n用户建议通过API请求获取对话数据，以便构建自定义的数据处理方案。\nUsers suggest obtaining conversation data via API requests to build custom data processing solutions.\n\n一种替代方案是用户可以通过编程方式使用providers，并将数据自行存储。\nAn alternative is for users to programmatically use providers and store the data themselves.\n\n研究目的包括标注、分析用户需求以及研究人类对各种语言模型行为的反应，如学习人类反应 $R(LM)$。\nResearch purposes include labeling, analyzing user needs, and studying human reactions to various language model behavior, such as learning human reaction $R(LM)$."
}