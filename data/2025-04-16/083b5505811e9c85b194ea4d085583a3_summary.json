{
  "title": "Cohere on Hugging Face Inference Providers ğŸ”¥",
  "link": "https://huggingface.co/blog/inference-providers-cohere",
  "published": "2025-04-16",
  "summary": "**Abstract:**\n\nWe announce Cohere's integration as a supported Inference Provider on Hugging Face Hub.\næˆ‘ä»¬å®£å¸ƒ Cohere å·²é›†æˆåˆ° Hugging Face Hub ä½œä¸ºæ”¯æŒçš„æ¨ç†æä¾›å•†ã€‚\n\nThis marks the first model creator to directly share and serve models on the Hub.\nè¿™æ ‡å¿—ç€ç¬¬ä¸€ä¸ªæ¨¡å‹åˆ›å»ºè€…ç›´æ¥åœ¨ Hub ä¸Šå…±äº«å’Œæä¾›æ¨¡å‹ã€‚\n\nCohere offers secure AI solutions for enterprise use, including Generative AI, Embeddings, and Ranking models.\nCohere ä¸ºä¼ä¸šç”¨é€”æä¾›å®‰å…¨çš„ AI è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç”Ÿæˆå¼ AIã€åµŒå…¥å’Œæ’åºæ¨¡å‹ã€‚\n\nCohereLabs supports fundamental research and innovation.\nCohereLabs æ”¯æŒåŸºç¡€ç ”ç©¶å’Œåˆ›æ–°ã€‚\n\nUsers can now run serverless inference on models like *CohereLabs/c4ai-command-a-03-2025* and *CohereLabs/aya-expanse-32b*.\nç”¨æˆ·ç°åœ¨å¯ä»¥åœ¨*CohereLabs/c4ai-command-a-03-2025*å’Œ*CohereLabs/aya-expanse-32b*ç­‰æ¨¡å‹ä¸Šè¿è¡Œæ— æœåŠ¡å™¨æ¨ç†ã€‚\n\n*CohereLabs/c4ai-command-a-03-2025* is optimized for enterprises needing fast, secure, high-quality AI with a 256k context length.\n*CohereLabs/c4ai-command-a-03-2025* é’ˆå¯¹éœ€è¦å¿«é€Ÿã€å®‰å…¨ã€é«˜è´¨é‡ AI ä¸”ä¸Šä¸‹æ–‡é•¿åº¦ä¸º 256k çš„ä¼ä¸šè¿›è¡Œäº†ä¼˜åŒ–ã€‚\n\nLeverage Cohere and Cohere Labs for advanced AI applications.\nåˆ©ç”¨ Cohere å’Œ Cohere Labs å®ç°é«˜çº§ AI åº”ç”¨ç¨‹åºã€‚\n\n**æ‘˜è¦ (Abstract)**\n\næœ¬æ–‡ä»‹ç»Cohereçš„å…ˆè¿›æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ¨¡å‹ï¼Œå…·æœ‰å¯éªŒè¯çš„å¼•æ–‡ã€æ™ºèƒ½ä½“å·¥å…·ä½¿ç”¨ã€ä¼ä¸šçº§å®‰å…¨æ€§å’Œå¼ºå¤§çš„å¤šè¯­è¨€æ€§èƒ½ï¼ˆæ”¯æŒ 23 ç§è¯­è¨€ï¼‰ã€‚\nThis paper introduces Cohere's advanced retrieval-augmented generation (RAG) models with verifiable citations, agentic tool use, enterprise-grade security, and strong multilingual performance (support for 23 languages).\n\nCohereLabs/aya-expanse-32b ä¸“æ³¨äºæœ€å…ˆè¿›çš„å¤šè¯­è¨€æ”¯æŒï¼Œåº”ç”¨äº†æœ€æ–°çš„å¤šè¯­è¨€é¢„è®­ç»ƒç ”ç©¶ã€‚\nCohereLabs/aya-expanse-32b focuses on state-of-the-art multilingual support, applying the latest research on multilingual pre-training.\n\nCohereLabs/c4ai-command-r7b-12-2024 é€‚ç”¨äºä½æˆæœ¬æˆ–ä½å»¶è¿Ÿç”¨ä¾‹ï¼Œåœ¨åŒç±»å¼€æºæ¨¡å‹ä¸­æä¾›æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰ 128K çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚\nCohereLabs/c4ai-command-r7b-12-2024 is ideal for low-cost or low-latency use cases, bringing state-of-the-art performance in its class of open-weight models, with a context length of 128K.\n\nCohereLabs/aya-vision-32b æ˜¯ä¸€ä¸ª 320 äº¿å‚æ•°æ¨¡å‹ï¼Œé’ˆå¯¹å„ç§è§†è§‰-è¯­è¨€ç”¨ä¾‹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œæ‰©å±•äº†å¤šæ¨¡æ€åŠŸèƒ½è‡³ 23 ç§è¯­è¨€ã€‚\nCohereLabs/aya-vision-32b is a 32-billion parameter model optimized for vision-language use cases, expanding multimodal capabilities to 23 languages.\n\nå¯ä»¥é€šè¿‡ Hugging Face Hub çš„ç½‘é¡µ UI æˆ–å®¢æˆ·ç«¯ SDK ç›´æ¥ä½¿ç”¨ Cohere æ¨¡å‹ã€‚\nCohere models can be directly used on the Hub either on the website UI or via the client SDKs.\n\n**Abstract:**\n\næœ¬æ–‡ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ Hugging Face Hub ä½œä¸ºæ¥å£ï¼Œè°ƒç”¨ Cohere çš„æ¨ç†æœåŠ¡ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆå’Œå¤šæ¨¡æ€å¤„ç†ã€‚\nThis paper introduces how to utilize Hugging Face Hub as an interface to invoke Cohere's inference services, including text generation and multimodal processing.\n\né€šè¿‡è®¾ç½® `provider=\"cohere\"` å’Œ API å¯†é’¥ï¼Œå¯ä»¥è½»æ¾åœ°è°ƒç”¨ Cohere çš„ç«¯ç‚¹ã€‚\nBy setting `provider=\"cohere\"` and the API key, Cohere's endpoints can be easily called.\n\næ–‡æœ¬ç”Ÿæˆç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `InferenceClient` å’Œ `chat.completions.create()` æ–¹æ³•ï¼Œä½¿ç”¨å¦‚ \"CohereLabs/c4ai-command-r7b-12-2024\" ç­‰æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚\nThe text generation example demonstrates how to use the `InferenceClient` and `chat.completions.create()` methods, using models like \"CohereLabs/c4ai-command-r7b-12-2024\" for dialogue.\n\nå¤šæ¨¡æ€å¤„ç†ç¤ºä¾‹åˆ™å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ base64 ç¼–ç åµŒå…¥å›¾åƒï¼Œå¹¶ä½¿ç”¨ \"CohereLabs/aya-vision-32b\" ç­‰æ¨¡å‹è¿›è¡Œå›¾åƒç†è§£ï¼Œåˆ©ç”¨ `image_url = f\"data:image/jpeg;base64,{base64_image}\"` ä¼ é€’å›¾åƒæ•°æ®ã€‚\nThe multimodal processing example demonstrates how to embed images via base64 encoding and utilize models such as \"CohereLabs/aya-vision-32b\" for image understanding, passing image data using `image_url = f\"data:image/jpeg;base64,{base64_image}\"`.\n\n**Abstract**\n\nThis work demonstrates calling Cohere's Command R7B model using the OpenAI client library via inference providers.\næœ¬ç ”ç©¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡Inference Providersä½¿ç”¨OpenAIå®¢æˆ·ç«¯åº“è°ƒç”¨Cohereçš„Command R7Bæ¨¡å‹ã€‚\n\nThe implementation utilizes a custom base URL (e.g., `\"https://router.huggingface.co/cohere/compatibility/v1\"`) and API key for authentication.\nè¯¥å®ç°ä½¿ç”¨è‡ªå®šä¹‰çš„ base URL (ä¾‹å¦‚, `\"https://router.huggingface.co/cohere/compatibility/v1\"`) å’Œ API å¯†é’¥è¿›è¡Œèº«ä»½éªŒè¯ã€‚\n\nFurthermore, we explore agentic tool use, defining a `get_flight_info` function with parameters for origin (`loc_origin`) and destination (`loc_destination`) airports.\næ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†agenticå·¥å…·çš„ä½¿ç”¨ï¼Œå®šä¹‰äº†ä¸€ä¸ª `get_flight_info` å‡½æ•°ï¼Œå…¶å‚æ•°åŒ…æ‹¬èµ·å§‹æœºåœº(`loc_origin`)å’Œç›®æ ‡æœºåœº(`loc_destination`)ã€‚\n\nThe tool definition is then incorporated into the model's chat template, enabling the model to make appropriate `tool_calls` during inference.\nç„¶åï¼Œå·¥å…·å®šä¹‰è¢«æ•´åˆåˆ°æ¨¡å‹çš„èŠå¤©æ¨¡æ¿ä¸­ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œé€‚å½“çš„ `tool_calls`ã€‚\n\n**Abstract:**\n\nThis work demonstrates the integration of a large language model (LLM) for flight information retrieval using the Hugging Face InferenceClient. This work utilizes a Cohere model `CohereLabs/c4ai-command-r7b-12-2024`.\næœ¬æ–‡å±•ç¤ºäº†ä½¿ç”¨Hugging Face InferenceClienté›†æˆå¤§å‹è¯­è¨€æ¨¡å‹(LLM)è¿›è¡Œèˆªç­ä¿¡æ¯æ£€ç´¢ã€‚This work utilizes a Cohere model `CohereLabs/c4ai-command-r7b-12-2024`.\n\nThe system processes a multi-turn conversation, including developer's date info, user's flight query (Miami to Seattle), and assistant's `tool_calls` using a function `get_flight_info` with arguments like `{ \"loc_destination\": \"Seattle\", \"loc_origin\": \"Miami\" }`.\nè¯¥ç³»ç»Ÿå¤„ç†å¤šè½®å¯¹è¯ï¼ŒåŒ…æ‹¬å¼€å‘äººå‘˜çš„æ—¥æœŸä¿¡æ¯ã€ç”¨æˆ·çš„èˆªç­æŸ¥è¯¢ï¼ˆè¿ˆé˜¿å¯†åˆ°è¥¿é›…å›¾ï¼‰ä»¥åŠåŠ©æ‰‹ä½¿ç”¨å‡½æ•°`get_flight_info`çš„`tool_calls`ï¼Œå‚æ•°å¦‚`{ \"loc_destination\": \"Seattle\", \"loc_origin\": \"Miami\" }`ã€‚\n\nThe tool provides the flight information, `Miami to Seattle, May 1st, 10 AM.`, which returns to the LLM.\nè¯¥å·¥å…·æä¾›äº†èˆªç­ä¿¡æ¯ï¼Œ`Miami to Seattle, May 1st, 10 AM.`ï¼Œè¿”å›ç»™LLMã€‚\n\nBilling information is provided, emphasizing the standard Cohere API rates and potential Inference credits for PRO users.\næä¾›äº†è´¦å•ä¿¡æ¯ï¼Œå¼ºè°ƒäº†æ ‡å‡†çš„Cohere APIè´¹ç‡å’ŒPROç”¨æˆ·çš„æ½œåœ¨Inference creditsã€‚\n\nThe paper also mentions related articles and community feedback.\næœ¬æ–‡è¿˜æåŠäº†ç›¸å…³æ–‡ç« å’Œç¤¾åŒºåé¦ˆã€‚\n\n**Abstract**\n\næœ¬æ–‡è®¨è®ºäº†ç”¨æˆ·å¯¹èŠå¤©è®°å½•APIè®¿é—®çš„éœ€æ±‚ï¼Œä»¥ä¾¿è¿›è¡Œæ•°æ®æ ‡æ³¨å’Œç”¨æˆ·è¡Œä¸ºç ”ç©¶ã€‚\nThis paper discusses the user demand for API access to chat logs for data labeling and user behavior research.\n\nç›®å‰ï¼Œè¯¥åŠŸèƒ½å°šæœªå®ç°ï¼Œä½†å·²è¢«å¼€å‘è€…è€ƒè™‘ã€‚\nCurrently, this functionality is not implemented but is under consideration by the developers.\n\nç”¨æˆ·å»ºè®®é€šè¿‡APIè¯·æ±‚è·å–å¯¹è¯æ•°æ®ï¼Œä»¥ä¾¿æ„å»ºè‡ªå®šä¹‰çš„æ•°æ®å¤„ç†æ–¹æ¡ˆã€‚\nUsers suggest obtaining conversation data via API requests to build custom data processing solutions.\n\nä¸€ç§æ›¿ä»£æ–¹æ¡ˆæ˜¯ç”¨æˆ·å¯ä»¥é€šè¿‡ç¼–ç¨‹æ–¹å¼ä½¿ç”¨providersï¼Œå¹¶å°†æ•°æ®è‡ªè¡Œå­˜å‚¨ã€‚\nAn alternative is for users to programmatically use providers and store the data themselves.\n\nç ”ç©¶ç›®çš„åŒ…æ‹¬æ ‡æ³¨ã€åˆ†æç”¨æˆ·éœ€æ±‚ä»¥åŠç ”ç©¶äººç±»å¯¹å„ç§è¯­è¨€æ¨¡å‹è¡Œä¸ºçš„ååº”ï¼Œå¦‚å­¦ä¹ äººç±»ååº” $R(LM)$ã€‚\nResearch purposes include labeling, analyzing user needs, and studying human reactions to various language model behavior, such as learning human reaction $R(LM)$."
}