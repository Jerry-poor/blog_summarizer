# HF åšå®¢æ—¥æŠ¥ â€” 2025-04-16

ä»¥ä¸‹å…±æœ‰ 3 ç¯‡åšæ–‡ï¼Œæ‘˜è¦å¦‚ä¸‹ï¼š

## [17 Reasons Why Gradio Isn't Just Another UI Library](https://huggingface.co/blog/why-gradio-stands-out) ï¼ˆ2025-04-16ï¼‰

å¥½çš„ï¼Œä¸‹é¢æ˜¯è¯¥æ–‡ç« çš„ä¸­è‹±åŒè¯­æ‘˜è¦ï¼Œä¿ç•™äº†å…¬å¼ä¸æœ¯è¯­ï¼š

**æ‘˜è¦ï¼š**

**è‹±æ–‡:**

This article highlights 17 reasons why Gradio is more than just a UI library, positioning it as a framework for interacting with machine learning models through UIs and APIs.  Gradio offers features such as universal API access through official SDKs in Python (`gradio_client`) and JavaScript (`@gradio/client`), as well as support for cURL API access, with automatic REST API endpoint generation. Other key features include interactive API recorders, server-side rendering for fast ML apps, automatic queue management, high-performance streaming for real-time outputs, integrated multi-page application support, client-side function execution with Groovy, comprehensive theming, dynamic interfaces, visual interface development with Gradio Sketch, PWA support, in-browser execution with Gradio Lite, AI-assisted tooling, hassle-free app sharing, enterprise-grade security, enhanced Dataframe component, and Deep Links for sharing app states. The article emphasizes Gradio's focus on performance, security, and responsiveness for building powerful AI applications.

**ä¸­æ–‡:**

æœ¬æ–‡å¼ºè°ƒäº† Gradio ä¸ä»…ä»…æ˜¯ä¸€ä¸ª UI åº“çš„ 17 ä¸ªåŸå› ï¼Œè€Œæ˜¯å°†å…¶å®šä½ä¸ºä¸€ä¸ªé€šè¿‡ UI å’Œ API ä¸æœºå™¨å­¦ä¹ æ¨¡å‹äº¤äº’çš„æ¡†æ¶ã€‚Gradio æä¾›äº†è¯¸å¦‚é€šç”¨ API è®¿é—®çš„åŠŸèƒ½ï¼Œé€šè¿‡å®˜æ–¹ Python (`gradio_client`) å’Œ JavaScript (`@gradio/client`) çš„ SDKï¼Œä»¥åŠå¯¹ cURL API è®¿é—®çš„æ”¯æŒï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆ REST API ç«¯ç‚¹ã€‚å…¶ä»–å…³é”®ç‰¹æ€§åŒ…æ‹¬ï¼šäº¤äº’å¼ API è®°å½•å™¨ã€ç”¨äºå¿«é€Ÿ ML åº”ç”¨çš„æœåŠ¡å™¨ç«¯æ¸²æŸ“ã€è‡ªåŠ¨é˜Ÿåˆ—ç®¡ç†ã€ç”¨äºå®æ—¶è¾“å‡ºçš„é«˜æ€§èƒ½æµå¼ä¼ è¾“ã€é›†æˆçš„å¤šé¡µé¢åº”ç”¨ç¨‹åºæ”¯æŒã€ä½¿ç”¨ Groovy çš„å®¢æˆ·ç«¯å‡½æ•°æ‰§è¡Œã€å…¨é¢çš„ä¸»é¢˜ç³»ç»Ÿã€åŠ¨æ€ç•Œé¢ã€ä½¿ç”¨ Gradio Sketch çš„å¯è§†åŒ–ç•Œé¢å¼€å‘ã€PWA æ”¯æŒã€ä½¿ç”¨ Gradio Lite çš„æµè§ˆå™¨å†…æ‰§è¡Œã€AI è¾…åŠ©å·¥å…·ã€è½»æ¾çš„åº”ç”¨ç¨‹åºå…±äº«ã€ä¼ä¸šçº§å®‰å…¨æ€§ã€å¢å¼ºçš„ Dataframe ç»„ä»¶ä»¥åŠç”¨äºå…±äº«åº”ç”¨ç¨‹åºçŠ¶æ€çš„æ·±åº¦é“¾æ¥ã€‚æ–‡ç« å¼ºè°ƒäº† Gradio å¯¹æ€§èƒ½ã€å®‰å…¨æ€§å’Œå“åº”æ€§çš„å…³æ³¨ï¼Œæ—¨åœ¨æ„å»ºå¼ºå¤§çš„ AI åº”ç”¨ç¨‹åºã€‚

## Gradio App Featuresæ‘˜è¦ (Summary of Gradio App Features)

**ä¸­æ–‡:**

Gradioåº”ç”¨ç¨‹åºæä¾›ä»¥ä¸‹å…³é”®ç‰¹æ€§ï¼š

1.  **è‡ªåŠ¨ç”Ÿæˆçš„APIæ–‡æ¡£ï¼š** é€šè¿‡â€œView APIâ€é“¾æ¥è®¿é—®ï¼Œæ–¹ä¾¿ç”¨æˆ·äº†è§£APIæ¥å£ã€‚
2.  **å®¢æˆ·ç«¯åº“ï¼š** åŒ…å«é«˜çº§åŠŸèƒ½ï¼Œå¦‚æ–‡ä»¶å¤„ç†å’ŒHugging Face Spaceå¤åˆ¶ï¼Œæ–¹ä¾¿ç”¨æˆ·é€šè¿‡ç¼–ç¨‹æ–¹å¼ä¸Gradioåº”ç”¨äº¤äº’ã€‚
3.  **äº¤äº’å¼APIå½•åˆ¶å™¨ï¼š** ä»Gradio 4.26ç‰ˆæœ¬å¼€å§‹å¼•å…¥ï¼Œå¯ä»¥å®æ—¶æ•è·UIäº¤äº’ï¼Œå¹¶è‡ªåŠ¨ç”ŸæˆPythonæˆ–JavaScriptä»£ç ï¼Œç”¨äºè®°å½•APIçš„ä½¿ç”¨æ–¹æ³•ã€‚
4.  **æœåŠ¡å™¨ç«¯æ¸²æŸ“ (SSR)ï¼š** ä»Gradio 5.0ç‰ˆæœ¬å¼€å§‹å¼•å…¥ï¼Œæ˜¾è‘—æå‡äº†åº”ç”¨ç¨‹åºçš„åŠ è½½é€Ÿåº¦å’Œæ€§èƒ½ã€‚SSRåœ¨æœåŠ¡å™¨ç«¯é¢„æ¸²æŸ“UIï¼Œæ¶ˆé™¤äº†åŠ è½½åŠ¨ç”»ï¼Œå®ç°äº†æ›´å¿«çš„åˆå§‹é¡µé¢åŠ è½½ï¼Œå¹¶æ”¹å–„äº†å·²å‘å¸ƒåº”ç”¨çš„SEOã€‚SSRä¼šè‡ªåŠ¨åœ¨Hugging Face Spaceséƒ¨ç½²ä¸­å¯ç”¨ã€‚

**Gradioçš„ä¼˜åŠ¿:**

*   å¤§å¤šæ•°å…¶ä»–Pythonæ¡†æ¶ç¼ºå°‘å®˜æ–¹APIè®¿é—®æœºåˆ¶ã€‚Gradioä»å•ä¸€å®ç°è‡ªåŠ¨ç”ŸæˆUIå’ŒAPIç«¯ç‚¹ï¼ŒåŒ…æ‹¬æ–‡æ¡£ã€‚
*   APIå½•åˆ¶å™¨å¯ä»¥è½»æ¾è„šæœ¬åŒ–UIäº¤äº’ï¼Œè¿™åœ¨å¤§å¤šæ•°å…¶ä»–Pythonå’ŒWebæ¡†æ¶ä¸­éš¾ä»¥å®ç°ã€‚
*   ä¼ ç»Ÿçš„Python UIæ¡†æ¶ä»…é™äºå®¢æˆ·ç«¯æ¸²æŸ“ã€‚

**è‹±æ–‡:**

Gradio apps offer the following key features:

1.  **Automatically-generated API documentation:** Accessible through the "View API" link, providing easy access to API interface information.
2.  **Client libraries:** Include advanced features like file handling and Hugging Face Space duplication, facilitating programmatic interaction with Gradio apps.
3.  **Interactive API Recorder:** Introduced in Gradio version 4.26, allowing real-time capture of UI interactions and automatic generation of Python or JavaScript code for documenting API usage.
4.  **Server-Side Rendering (SSR):** Introduced in Gradio version 5.0, significantly improving application loading speed and performance. SSR pre-renders the UI on the server, eliminating loading spinners, enabling faster initial page load times, and improving SEO for published applications. SSR is automatically enabled for Hugging Face Spaces deployments.

**What Sets Gradio Apart:**

*   Most other Python frameworks lack official API access mechanisms. Gradio automatically generates both UI and API endpoints from a single implementation, including documentation.
*   The API Recorder allows easy scripting of UI interactions, which is difficult to achieve in most other Python and Web frameworks.
*   Traditional Python UI frameworks are limited to client-side rendering.

Okay, here's a summary of the provided text, with both English and Chinese versions, preserving formulas and terminology:

**English Summary:**

Gradio simplifies building high-performance ML web applications by providing features like automatic queue management and high-performance streaming. Unlike other Python frameworks, Gradio offers built-in queue management, eliminating the need for manual implementation of queuing systems that would be required for popular web frameworks and allowing for the creation of GPU-intensive or viral ML applications. Gradio's queuing system automatically handles diverse tasks (GPU-intensive computations, streaming, non-ML tasks), enables scaling to thousands of concurrent users, provides real-time queue status updates via Server-Side Events, and allows configuring concurrency limits using `concurrency_id`. Furthermore, Gradio supports real-time, low-latency streaming using Python generators with `yield` statements, enabling token-by-token text generation, step-by-step image generation, and smooth audio/video streaming via HTTP Live Streaming (HLS) protocol, and provides WebRTC/WebSocket API for real-time applications via `FastRTC`.  This is all achieved while maintaining a pure Python development experience, although Node.js installation is required.

**Chinese Summary:**

Gradioé€šè¿‡æä¾›è‡ªåŠ¨é˜Ÿåˆ—ç®¡ç†å’Œé«˜æ€§èƒ½æµå¼ä¼ è¾“ç­‰åŠŸèƒ½ï¼Œç®€åŒ–äº†é«˜æ€§èƒ½æœºå™¨å­¦ä¹ Webåº”ç”¨ç¨‹åºçš„æ„å»ºã€‚ä¸å…¶ä»–Pythonæ¡†æ¶ä¸åŒï¼ŒGradioæä¾›äº†å†…ç½®çš„é˜Ÿåˆ—ç®¡ç†ï¼Œæ— éœ€åƒä½¿ç”¨æµè¡Œçš„Webæ¡†æ¶é‚£æ ·æ‰‹åŠ¨å®ç°é˜Ÿåˆ—ç³»ç»Ÿï¼Œä»è€Œå¯ä»¥åˆ›å»ºGPUå¯†é›†å‹æˆ–ç—…æ¯’å¼MLåº”ç”¨ç¨‹åºã€‚Gradioçš„é˜Ÿåˆ—ç³»ç»Ÿè‡ªåŠ¨å¤„ç†å„ç§ä»»åŠ¡ï¼ˆGPUå¯†é›†å‹è®¡ç®—ã€æµå¼ä¼ è¾“ã€éMLä»»åŠ¡ï¼‰ï¼Œæ”¯æŒæ‰©å±•åˆ°æ•°åƒå¹¶å‘ç”¨æˆ·ï¼Œé€šè¿‡Server-Side Eventsæä¾›å®æ—¶é˜Ÿåˆ—çŠ¶æ€æ›´æ–°ï¼Œå¹¶å…è®¸ä½¿ç”¨`concurrency_id`é…ç½®å¹¶å‘é™åˆ¶ã€‚æ­¤å¤–ï¼ŒGradioæ”¯æŒä½¿ç”¨å¸¦æœ‰`yield`è¯­å¥çš„Pythonç”Ÿæˆå™¨è¿›è¡Œå®æ—¶ã€ä½å»¶è¿Ÿæµå¼ä¼ è¾“ï¼Œä»è€Œå®ç°token-by-tokenæ–‡æœ¬ç”Ÿæˆã€step-by-stepå›¾åƒç”Ÿæˆä»¥åŠé€šè¿‡HTTP Live Streaming (HLS) åè®®å®ç°æµç•…çš„éŸ³é¢‘/è§†é¢‘æµï¼Œå¹¶é€šè¿‡`FastRTC`æä¾›ç”¨äºå®æ—¶åº”ç”¨ç¨‹åºçš„WebRTC/WebSocket APIã€‚æ‰€æœ‰è¿™äº›éƒ½åœ¨ä¿æŒçº¯Pythonå¼€å‘ä½“éªŒçš„åŒæ—¶å®ç°ï¼Œå°½ç®¡éœ€è¦å®‰è£…Node.jsã€‚

å¥½çš„ï¼Œè¿™é‡Œæ˜¯è¯¥å†…å®¹çš„æ‘˜è¦ï¼ŒåŒ…å«ä¸­è‹±æ–‡ç‰ˆæœ¬ï¼Œå¹¶ä¿ç•™äº†å…¬å¼å’Œæœ¯è¯­ï¼š

**æ‘˜è¦ (ä¸­æ–‡)**

Gradio 5 çš„æ”¹è¿›åŒ…æ‹¬ï¼š

*   **æµå¼ä¼ è¾“å¢å¼º:** Gradio å…è®¸ä½¿ç”¨ FastRTC å’Œ Gradio å®Œå…¨ä½¿ç”¨ Python åˆ›å»ºå®æ—¶éŸ³é¢‘/è§†é¢‘æµåº”ç”¨ç¨‹åºï¼Œè€Œå…¶ä»–æ¡†æ¶éœ€è¦æ‰‹åŠ¨çº¿ç¨‹ç®¡ç†å’Œè½®è¯¢æ›´æ–°ï¼Œæˆ–éœ€è¦è‡ªå®šä¹‰ WebSocket/WebRTC å®ç°ã€‚
*   **é›†æˆå¤šé¡µé¢åº”ç”¨æ”¯æŒ:** Gradio ç°åœ¨åŸç”Ÿæ”¯æŒå¤šé¡µé¢åº”ç”¨ï¼Œå…è®¸å¼€å‘è€…æ„å»ºæ›´å…¨é¢çš„ AI/ML åº”ç”¨ã€‚å®ƒæä¾›è‡ªåŠ¨ URL è·¯ç”±å’Œå¯¼èˆªæ ç”Ÿæˆï¼Œå¹¶åœ¨é¡µé¢ä¹‹é—´å…±äº«åç«¯èµ„æºï¼ˆå¦‚é˜Ÿåˆ—ï¼‰ã€‚è¿™æé«˜äº†æ–‡ä»¶å¯ç»´æŠ¤æ€§å’Œæµ‹è¯•æ€§ã€‚Gradio é€šè¿‡ç®€å•çš„ Python å£°æ˜æä¾›è‡ªåŠ¨è·¯ç”±å’Œå¯¼èˆªæ ï¼Œæ— éœ€åƒå…¶ä»–æ¡†æ¶é‚£æ ·ä¸ºæ¯ä¸ªé¡µé¢ç¼–å†™å•ç‹¬çš„è„šæœ¬æˆ–æ˜¾å¼è®¾ç½®è·¯ç”±ã€‚
*   **ä½¿ç”¨ Groovy çš„æ–°å®¢æˆ·ç«¯å‡½æ•°æ‰§è¡Œ:** Gradio 5 å¼•å…¥äº† Groovyï¼Œä¸€ä¸ªè‡ªåŠ¨ Python åˆ° JavaScript çš„è½¬æ¢åº“ï¼Œå…è®¸åœ¨å®¢æˆ·ç«¯ç›´æ¥æ‰§è¡Œ Python å‡½æ•° (é€šè¿‡ `js=True` æ ‡è®°)ï¼Œæ— éœ€æœåŠ¡å™¨å¾€è¿”å³å¯å®ç°å³æ—¶ UI å“åº”ã€‚è¿™å‡å°‘äº†ç®€å• UI äº¤äº’çš„å»¶è¿Ÿï¼Œå¹¶é™ä½äº†æœåŠ¡å™¨è´Ÿè½½ã€‚

**æ‘˜è¦ (English)**

Gradio 5 improvements include:

*   **Streaming Improvements:** Gradio allows creating real-time audio/video streaming applications entirely in Python with FastRTC and Gradio. Other frameworks require manual thread management and polling for streaming updates, or custom WebSocket/WebRTC implementations.
*   **Integrated Multi-Page Application Support:** Gradio now natively supports multi-page applications, enabling developers to build more comprehensive AI/ML applications. It provides automatic URL routing and navigation bar generation and shares backend resources (such as the queue) across pages. This improves file maintainability and testing. Gradio offers automatic routing and navigation bars using simple Python declarations, eliminating the need for separate scripts for each page or explicit routing setup like other frameworks.
*   **New Client-Side Function Execution With Groovy:** Gradio 5 introduces Groovy, an automatic Python-to-JavaScript transpilation library, allowing direct execution of Python functions on the client-side (via the `js=True` flag) for instant UI responsiveness without server roundtrips. This reduces latency for simple UI interactions and lowers server load.

## æ‘˜è¦ (Summary)

**è‹±æ–‡ (English):**

Gradio distinguishes itself by offering a single-language (Python) development experience through automatic transpilation to JavaScript, enabling web-native performance without requiring separate JavaScript codebases, unlike most other Python frameworks.  It features a comprehensive theming system with ready-to-use presets (Monochrome, Soft, Ocean, Glass, etc.) including built-in dark mode support, automatic mobile responsiveness, and accessibility features for screen readers. Gradio provides ML-specific UI components such as Undo/Retry/Like buttons for chat interfaces, ImageEditor and AnnotatedImage components for segmentation/masking, and ImageSlider for image-to-image transformations. Recent enhancements focus on UI features for Reasoning LLMs, Agents, Multistep Agents, Nested Thoughts, and Nested Agents within chat interfaces. Furthermore, Gradio allows creating professional UIs without web design expertise and offers a dynamic interface feature using the `@gr.render()` decorator. This sets Gradio apart from other Python frameworks that offer limited color customization and require manual theme and CSS implementation.

**ä¸­æ–‡ (Chinese):**

Gradio çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºï¼Œå®ƒé€šè¿‡è‡ªåŠ¨è½¬è¯‘ä¸º JavaScriptï¼Œæä¾›äº†ä¸€ç§å•è¯­è¨€ (Python) å¼€å‘ä½“éªŒï¼Œä»è€Œå®ç°äº† web åŸç”Ÿæ€§èƒ½ï¼Œæ— éœ€åƒå¤§å¤šæ•°å…¶ä»– Python æ¡†æ¶é‚£æ ·ä½¿ç”¨å•ç‹¬çš„ JavaScript ä»£ç åº“ã€‚ å®ƒå…·æœ‰å…¨é¢çš„ä¸»é¢˜ç³»ç»Ÿï¼Œæä¾›å³ç”¨å‹é¢„è®¾ä¸»é¢˜ï¼ˆä¾‹å¦‚ Monochromeã€Softã€Oceanã€Glass ç­‰ï¼‰ï¼ŒåŒ…æ‹¬å†…ç½®çš„æš—é»‘æ¨¡å¼æ”¯æŒã€è‡ªåŠ¨çš„ç§»åŠ¨å“åº”èƒ½åŠ›å’Œå±å¹•é˜…è¯»å™¨çš„å¯è®¿é—®æ€§åŠŸèƒ½ã€‚ Gradio æä¾›ç‰¹å®šäº ML çš„ UI ç»„ä»¶ï¼Œä¾‹å¦‚èŠå¤©ç•Œé¢çš„æ’¤æ¶ˆ/é‡åš/å–œæ¬¢æŒ‰é’®ã€ç”¨äºåˆ†å‰²/æ©ç çš„ ImageEditor å’Œ AnnotatedImage ç»„ä»¶ï¼Œä»¥åŠç”¨äºå›¾åƒåˆ°å›¾åƒè½¬æ¢çš„ ImageSliderã€‚ æœ€è¿‘çš„å¢å¼ºåŠŸèƒ½ä¾§é‡äºèŠå¤©ç•Œé¢ä¸­æ¨ç† LLMã€Agentã€å¤šæ­¥ Agentã€åµŒå¥—æ€ç»´å’ŒåµŒå¥— Agent çš„ UI åŠŸèƒ½ã€‚ æ­¤å¤–ï¼ŒGradio å…è®¸åœ¨æ²¡æœ‰ Web è®¾è®¡ä¸“ä¸šçŸ¥è¯†çš„æƒ…å†µä¸‹åˆ›å»ºä¸“ä¸šçš„ UIï¼Œå¹¶ä½¿ç”¨ `@gr.render()` è£…é¥°å™¨æä¾›åŠ¨æ€ç•Œé¢åŠŸèƒ½ã€‚ è¿™ä½¿å¾— Gradio ä¸å…¶ä»–æä¾›æœ‰é™é¢œè‰²è‡ªå®šä¹‰å¹¶éœ€è¦æ‰‹åŠ¨ä¸»é¢˜å’Œ CSS å®ç°çš„ Python æ¡†æ¶åŒºåˆ†å¼€æ¥ã€‚

**Key Terms & Formula (å…³é”®æœ¯è¯­å’Œå…¬å¼):**

*   `@gr.render()`: Decorator for dynamic interfaces. (åŠ¨æ€ç•Œé¢çš„è£…é¥°å™¨)
*   UI Components (ç”¨æˆ·ç•Œé¢ç»„ä»¶): Undo/Retry/Like buttons, ImageEditor, AnnotatedImage, ImageSlider. (æ’¤æ¶ˆ/é‡åš/å–œæ¬¢æŒ‰é’®ã€å›¾åƒç¼–è¾‘å™¨ã€æ³¨é‡Šå›¾åƒã€å›¾åƒæ»‘å—)
*   Theming System (ä¸»é¢˜ç³»ç»Ÿ): Monochrome, Soft, Ocean, Glass. (å•è‰²ã€æŸ”å’Œã€æµ·æ´‹ã€ç»ç’ƒ)
*   LLMs, Agents, Multistep Agents, Nested Thoughts, Nested Agents (LLMã€Agentã€å¤šæ­¥ Agentã€åµŒå¥—æ€ç»´ã€åµŒå¥— Agent)

## æ‘˜è¦ (Summary):

**English:**

Gradio now supports dynamic UI updates and a visual development environment, significantly enhancing its capabilities. Developers can now add new components and event listeners dynamically based on user interaction and state, enabling on-the-fly UI modifications based on model outputs or workflow.  Gradio's `.render()` method allows rendering Blocks within other Blocks.  Furthermore, Gradio Sketch introduces a no-code visual interface development tool (WYSIWYG editor) for building Gradio applications. Users can visually add components, define events, attach functions, and generate the corresponding code automatically, including code for inference functions.  Finally, Gradio offers Progressive Web App (PWA) support.

**Key Features:**

*   **Dynamic UI Updates:**  Add components and listeners dynamically based on user interaction/state.
*   **`render()` method:** Render Blocks within other Blocks.
*   **Gradio Sketch:** No-code visual interface development (WYSIWYG editor) for building Gradio applications.
*   **PWA Support:** Gradio provides Progressive Web App capabilities.

**ä¼˜åŠ¿ (Advantages):**

*   **Dynamic UI:** Simplifies the creation of sophisticated and responsive interfaces using Python, unlike other frameworks that require JavaScript for interface updates.
*   **Gradio Sketch:** Reduces the learning curve for non-coders and accelerates application development.
*   **PWA:** Provides regular web pages.

---

**ä¸­æ–‡:**

Gradioç°åœ¨æ”¯æŒåŠ¨æ€UIæ›´æ–°å’Œä¸€ä¸ªå¯è§†åŒ–å¼€å‘ç¯å¢ƒï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†å…¶åŠŸèƒ½ã€‚å¼€å‘è€…ç°åœ¨å¯ä»¥åŸºäºç”¨æˆ·äº¤äº’å’ŒçŠ¶æ€åŠ¨æ€åœ°æ·»åŠ æ–°ç»„ä»¶å’Œäº‹ä»¶ç›‘å¬å™¨ï¼Œä»è€Œèƒ½å¤Ÿæ ¹æ®æ¨¡å‹è¾“å‡ºæˆ–å·¥ä½œæµç¨‹è¿›è¡Œå³æ—¶UIä¿®æ”¹ã€‚Gradioçš„ `.render()` æ–¹æ³•å…è®¸åœ¨ä¸€ä¸ªBlockä¸­æ¸²æŸ“å¦ä¸€ä¸ªBlockã€‚æ­¤å¤–ï¼ŒGradio Sketch å¼•å…¥äº†ä¸€ä¸ªæ— ä»£ç çš„å¯è§†åŒ–ç•Œé¢å¼€å‘å·¥å…·ï¼ˆWYSIWYGç¼–è¾‘å™¨ï¼‰ï¼Œç”¨äºæ„å»ºGradioåº”ç”¨ç¨‹åºã€‚ç”¨æˆ·å¯ä»¥å¯è§†åŒ–åœ°æ·»åŠ ç»„ä»¶ã€å®šä¹‰äº‹ä»¶ã€é™„åŠ å‡½æ•°ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„ä»£ç ï¼ŒåŒ…æ‹¬æ¨ç†å‡½æ•°çš„ä»£ç ã€‚ æœ€åï¼ŒGradioæä¾›æ¸è¿›å¼Webåº”ç”¨ï¼ˆPWAï¼‰æ”¯æŒã€‚

**å…³é”®ç‰¹æ€§ï¼š**

*   **åŠ¨æ€ UI æ›´æ–°:** åŸºäºç”¨æˆ·äº¤äº’/çŠ¶æ€åŠ¨æ€æ·»åŠ ç»„ä»¶å’Œç›‘å¬å™¨ã€‚
*   **`render()` æ–¹æ³•:** åœ¨å¦ä¸€ä¸ªBlockä¸­æ¸²æŸ“Blocksã€‚
*   **Gradio Sketch:** ç”¨äºæ„å»ºGradioåº”ç”¨ç¨‹åºçš„æ— ä»£ç å¯è§†åŒ–ç•Œé¢å¼€å‘ï¼ˆWYSIWYGç¼–è¾‘å™¨ï¼‰ã€‚
*   **PWA æ”¯æŒ:** Gradioæä¾›æ¸è¿›å¼Webåº”ç”¨åŠŸèƒ½ã€‚

**ä¼˜åŠ¿ï¼š**

*   **åŠ¨æ€ UI:** ç®€åŒ–äº†ä½¿ç”¨Pythonåˆ›å»ºå¤æ‚ä¸”å“åº”å¼ç•Œé¢çš„è¿‡ç¨‹ï¼Œä¸åŒäºå…¶ä»–éœ€è¦JavaScriptè¿›è¡Œç•Œé¢æ›´æ–°çš„æ¡†æ¶ã€‚
*   **Gradio Sketch:** é™ä½äº†éç¼–ç äººå‘˜çš„å­¦ä¹ æ›²çº¿ï¼Œå¹¶åŠ é€Ÿäº†åº”ç”¨ç¨‹åºå¼€å‘ã€‚
*   **PWA:** æä¾›å¸¸è§„ç½‘é¡µã€‚

## æ‘˜è¦ (Summary):

**ä¸­æ–‡:**

Gradio é€šè¿‡ä»¥ä¸‹ç‰¹æ€§ç®€åŒ–äº†æœºå™¨å­¦ä¹  (ML) åº”ç”¨çš„å¼€å‘å’Œéƒ¨ç½²ï¼š

*   **æ¸è¿›å¼ Web åº”ç”¨ (PWA) æ”¯æŒ:** Gradio æä¾›åŸç”Ÿ PWA æ”¯æŒï¼Œå…è®¸åˆ›å»ºçœ‹ä¼¼å¹³å°ä¸“å±çš„å¯å®‰è£…åº”ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®å³å¯ç”¨äºç§»åŠ¨å’Œæ¡Œé¢å¹³å°ã€‚è¿™æ‰©å±•äº†ç”¨æˆ·è®¿é—®èŒƒå›´ï¼Œå¹¶èƒ½å¿«é€Ÿåˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰å›¾æ ‡çš„ç§»åŠ¨åº”ç”¨ã€‚
*   **æµè§ˆå™¨å†…æ‰§è¡Œ (Gradio Lite):**  åˆ©ç”¨ Pyodide (WebAssembly)ï¼ŒGradio Lite å®ç°äº†æµè§ˆå™¨ç«¯çš„æ‰§è¡Œï¼Œå…è®¸ä½¿ç”¨å®¢æˆ·ç«¯æ¨¡å‹æ¨ç†æœåŠ¡ï¼ˆå¦‚ Transformers.js å’Œ ONNXï¼‰æ„å»º ML æ¼”ç¤ºã€‚ ä¼˜åŠ¿åŒ…æ‹¬å¢å¼ºçš„éšç§ï¼ˆæ‰€æœ‰æ•°æ®ä¿ç•™åœ¨ç”¨æˆ·æµè§ˆå™¨ä¸­ï¼‰ã€é›¶æœåŠ¡å™¨éƒ¨ç½²æˆæœ¬å’Œç¦»çº¿æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚
*   **AI è¾…åŠ©å·¥å…·åŠ é€Ÿå¼€å‘:** Gradio å¼•å…¥äº†åˆ›æ–°åŠŸèƒ½æ¥åŠ é€Ÿ ML åº”ç”¨å¼€å‘å‘¨æœŸï¼ŒåŒ…æ‹¬çƒ­é‡è½½åŠŸèƒ½ã€ç”¨äºè‡ªç„¶è¯­è¨€é©±åŠ¨çš„åº”ç”¨ç”Ÿæˆçš„ AI Playgroundï¼Œä»¥åŠä¸ HuggingFace å’Œæ¨ç†æä¾›å•†çš„é›†æˆï¼Œå¯ä»¥ç”¨å•è¡Œä»£ç å¿«é€Ÿæ„å»ºåº”ç”¨åŸå‹ã€‚

**è‹±æ–‡:**

Gradio simplifies the development and deployment of Machine Learning (ML) applications through the following features:

*   **Progressive Web App (PWA) Support:** Gradio offers native PWA support, allowing the creation of installable platform-specific applications that appear so to the user, without the need for extra configurations for mobile and desktop platforms. This expands user access and enables rapid creation of mobile apps with custom icons.
*   **In-Browser Execution (Gradio Lite):** Utilizing Pyodide (WebAssembly), Gradio Lite enables browser-side execution, allowing the building of ML demos using client-side model inference services like Transformers.js and ONNX.  Benefits include enhanced privacy (all data stays in the user's browser), zero server costs for deployment, and offline-capable model inference.
*   **Accelerated Development with AI-Assisted Tooling:** Gradio introduces innovative features to accelerate the ML application development cycle, including a hot reload capability, AI Playground for natural language-driven app generation, and integrations with HuggingFace and Inference providers, enabling rapid prototyping of applications in a single line of code.

## æ‘˜è¦ (Summary)

**ä¸­æ–‡ï¼š**

Gradio å¯ä»¥é€šè¿‡ `gr.load()` ä¸å…¼å®¹ OpenAI çš„ API æ¥å£ä¸€èµ·ä½¿ç”¨ã€‚Gradio çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºå®ƒæä¾›äº†å³æ—¶çš„ UI åé¦ˆå’Œ AI è¾…åŠ©å¼€å‘ï¼Œä»è€Œå®ç°äº†å¿«é€Ÿå¼€å‘å’Œä¿®æ”¹æœºå™¨å­¦ä¹  (ML) åº”ç”¨ã€‚åº”ç”¨ç¨‹åºå¯ä»¥é€šè¿‡è®¾ç½® `demo.launch(share=True)` å‚æ•°ç”Ÿæˆä¸€ä¸ªå³æ—¶å…¬å…± URLï¼Œæ ¼å¼ä¸º `xxxxx.gradio.live`ï¼Œæœ‰æ•ˆæœŸä¸º 1 å‘¨ã€‚æ­¤å…±äº«é“¾æ¥ä½¿ç”¨ Fast Reverse Proxy (FRP) é€šè¿‡ Gradio çš„å…±äº«æœåŠ¡å™¨å»ºç«‹åˆ°æœ¬åœ°è¿è¡Œåº”ç”¨ç¨‹åºçš„å®‰å…¨ TLS é€šé“ã€‚å¯¹äºä¼ä¸šéƒ¨ç½²æˆ–éœ€è¦è‡ªå®šä¹‰åŸŸåæˆ–é¢å¤–å®‰å…¨æªæ–½çš„æƒ…å†µï¼Œå¯ä»¥æ‰˜ç®¡è‡ªå·±çš„ FRP æœåŠ¡å™¨ä»¥é¿å… 1 å‘¨çš„è¶…æ—¶ã€‚ä¸å…¶ä»–æ¡†æ¶ä¸åŒï¼ŒGradio æ— éœ€äº‘éƒ¨ç½²å’Œå¤§é‡é…ç½®å³å¯è½»æ¾å…±äº«åº”ç”¨ç¨‹åºï¼Œè€Œå…¶ä»– Web æ¡†æ¶åˆ™éœ€è¦æ‰‹åŠ¨æœåŠ¡å™¨è®¾ç½®å’Œæ‰˜ç®¡ã€‚

**è‹±æ–‡ï¼š**

Gradio can be used with any API endpoint that is compatible with OpenAI, achievable with `gr.load()`. It stands out by offering instant UI feedback and AI-assisted development, enabling rapid creation and modification of Machine Learning (ML) applications. You can generate an instant public URL by simply setting the parameter `demo.launch(share=True)`, creating an address in the format `xxxxx.gradio.live` that lasts for 1 week. This share link creates a secure TLS tunnel to your locally-running app through Gradio's share server using Fast Reverse Proxy (FRP). For enterprise deployments or scenarios requiring custom domains or additional security, you can host your own FRP server to avoid the 1-week timeout. Unlike other frameworks, Gradio offers instant sharing from your local development environment without cloud deployment and lots of configuration, while other Web frameworks require manual server setup and hosting.

## æ‘˜è¦ (Summary)

**è‹±æ–‡ (English):**

Gradio offers immediate collaboration and demonstration capabilities through share links without requiring hosting or port forwarding, making it ideal for rapid prototyping and gathering feedback on machine learning apps.  Gradio has evolved into a production-ready framework with enterprise-grade security, including third-party security audits and vulnerability assessments.  Security enhancements include hardened file handling and upload controls, configurable security settings via environment variables such as `GRADIO_ALLOWED_PATHS` and `GRADIO_SSR_MODE`.  Unlike other Python web frameworks, Gradio provides specialized security for ML deployment, including protected file upload handling and sanitized model I/O processing.  The enhanced dataframe component features multi-cell selection, row numbers, column pinning, search/filter functions, static columns, and improved accessibility.

**ä¸­æ–‡ (Chinese):**

Gradio é€šè¿‡åˆ†äº«é“¾æ¥æä¾›å³æ—¶åä½œå’Œæ¼”ç¤ºåŠŸèƒ½ï¼Œæ— éœ€æ‰˜ç®¡æˆ–ç«¯å£è½¬å‘ï¼Œéå¸¸é€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œæ”¶é›†æœºå™¨å­¦ä¹ åº”ç”¨ç¨‹åºçš„åé¦ˆã€‚Gradio å·²ç»å‘å±•æˆä¸ºä¸€ä¸ªå…·æœ‰ä¼ä¸šçº§å®‰å…¨æ€§çš„ã€å¯ç”¨äºç”Ÿäº§ç¯å¢ƒçš„æ¡†æ¶ï¼ŒåŒ…æ‹¬æ¥è‡ªç¬¬ä¸‰æ–¹çš„å®‰å…¨å®¡è®¡å’Œæ¼æ´è¯„ä¼°ã€‚å®‰å…¨å¢å¼ºåŠŸèƒ½åŒ…æ‹¬åŠ å¼ºçš„æ–‡ä»¶å¤„ç†å’Œä¸Šä¼ æ§åˆ¶ï¼Œä»¥åŠé€šè¿‡ç¯å¢ƒå˜é‡ï¼ˆä¾‹å¦‚ `GRADIO_ALLOWED_PATHS` å’Œ `GRADIO_SSR_MODE`ï¼‰è¿›è¡Œé…ç½®çš„å®‰å…¨è®¾ç½®ã€‚ ä¸å…¶ä»– Python Web æ¡†æ¶ä¸åŒï¼ŒGradio ä¸º ML éƒ¨ç½²æä¾›ä¸“é—¨çš„å®‰å…¨ä¿éšœï¼ŒåŒ…æ‹¬å—ä¿æŠ¤çš„æ–‡ä»¶ä¸Šä¼ å¤„ç†å’Œç»è¿‡æ¸…ç†çš„æ¨¡å‹ I/O å¤„ç†ã€‚ å¢å¼ºçš„ Dataframe ç»„ä»¶å…·æœ‰å¤šå•å…ƒæ ¼é€‰æ‹©ã€è¡Œå·ã€åˆ—å›ºå®šã€æœç´¢/ç­›é€‰åŠŸèƒ½ã€é™æ€åˆ—ä»¥åŠæ”¹è¿›çš„å¯è®¿é—®æ€§ã€‚

## æ‘˜è¦ (Summary):

**English:**

Gradio has evolved into an AI-focused framework for building complete web applications in Python without web development expertise. Innovations in Gradio 4 and 5, like Python-to-JavaScript transpilation, built-in queuing for resource-intensive models, real-time audio-video streaming with FastRTC, and server-side rendering, differentiate it from other frameworks by providing capabilities that often require extensive implementation work.  Key features include:

*   **Deep Links:** Enabled by the `gr.DeepLinkButton` component, they allow users to capture and share the exact state of an application, working with any public Gradio app (hosted or using `share=True`). This simplifies sharing of generated output without additional implementation.

Gradio handles infrastructure concerns, allowing developers to focus on model development while delivering polished UIs. It supports both rapid prototyping and production deployment.

**ä¸­æ–‡:**

Gradioå·²å‘å±•æˆä¸ºä¸€ä¸ªä»¥äººå·¥æ™ºèƒ½ä¸ºä¸­å¿ƒçš„æ¡†æ¶ï¼Œå¯ä»¥ä½¿ç”¨ Python æ„å»ºå®Œæ•´çš„ Web åº”ç”¨ç¨‹åºï¼Œè€Œæ— éœ€ Web å¼€å‘ä¸“ä¸šçŸ¥è¯†ã€‚Gradio 4 å’Œ 5 çš„åˆ›æ–°ï¼Œä¾‹å¦‚ Python åˆ° JavaScript çš„è½¬è¯‘ã€é’ˆå¯¹èµ„æºå¯†é›†å‹æ¨¡å‹çš„å†…ç½®é˜Ÿåˆ—ã€ä½¿ç”¨ FastRTC çš„å®æ—¶éŸ³è§†é¢‘æµå’ŒæœåŠ¡å™¨ç«¯æ¸²æŸ“ï¼Œä½¿å…¶ä¸å…¶ä»–æ¡†æ¶åŒºåˆ†å¼€æ¥ï¼Œå› ä¸ºå®ƒä»¬æä¾›äº†é€šå¸¸éœ€è¦å¤§é‡å®ç°å·¥ä½œæ‰èƒ½å®ç°çš„åŠŸèƒ½ã€‚å…³é”®ç‰¹æ€§åŒ…æ‹¬ï¼š

*   **æ·±åº¦é“¾æ¥ (Deep Links):** é€šè¿‡ `gr.DeepLinkButton` ç»„ä»¶å¯ç”¨ï¼Œå…è®¸ç”¨æˆ·æ•è·å’Œå…±äº«åº”ç”¨ç¨‹åºçš„ç²¾ç¡®çŠ¶æ€ï¼Œé€‚ç”¨äºä»»ä½•å…¬å…± Gradio åº”ç”¨ç¨‹åºï¼ˆæ‰˜ç®¡æˆ–ä½¿ç”¨ `share=True`ï¼‰ã€‚ è¿™ç®€åŒ–äº†ç”Ÿæˆè¾“å‡ºçš„å…±äº«ï¼Œè€Œæ— éœ€é¢å¤–çš„å®æ–½ã€‚

Gradio å¤„ç†åŸºç¡€è®¾æ–½é—®é¢˜ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿä¸“æ³¨äºæ¨¡å‹å¼€å‘ï¼ŒåŒæ—¶æä¾›å®Œå–„çš„ç”¨æˆ·ç•Œé¢ã€‚ å®ƒæ”¯æŒå¿«é€ŸåŸå‹è®¾è®¡å’Œç”Ÿäº§éƒ¨ç½²ã€‚

Here's a summary of the provided text, in both English and Chinese:

**English Summary:**

This text highlights the capabilities of Gradio, a tool that empowers a wide audience. It mentions a blog post celebrating reaching 1 million Gradio users (published April 4, 2025, by abidlabs) and introduces a new Gradio Dataframe feature (published March 24, 2025, by hmb). A community post reports an error encountered while using `torch.load()` in a Gradio space: `_pickle.UnpicklingError: invalid load key, 'v'`. The user is attempting to load a model and receives the error when unpickling. The space involves KokoroTTS for custom voices, and the user is asking about the correct `torch` version. Functionality for uploading images, audio, and video is also mentioned, along with a prompt to sign up or log in to comment.  The error stack trace contains: `torch.serialization.py`, `_pickle.UnpicklingError`, `torch.load(path, map_location='cuda', weights_only=False)['net'].items()`.

**Chinese Summary:**

è¿™æ®µæ–‡å­—å¼ºè°ƒäº† Gradio çš„åŠŸèƒ½ï¼Œå®ƒæ˜¯ä¸€ä¸ªèµ‹èƒ½å¹¿å¤§ç”¨æˆ·çš„å·¥å…·ã€‚ å®ƒæåˆ°äº†ä¸€ç¯‡åº†ç¥è¾¾åˆ° 100 ä¸‡ Gradio ç”¨æˆ·çš„åšå®¢æ–‡ç« ï¼ˆç”± abidlabs äº 2025 å¹´ 4 æœˆ 4 æ—¥å‘å¸ƒï¼‰ï¼Œå¹¶ä»‹ç»äº†ä¸€ä¸ªæ–°çš„ Gradio Dataframe åŠŸèƒ½ï¼ˆç”± hmb äº 2025 å¹´ 3 æœˆ 24 æ—¥å‘å¸ƒï¼‰ã€‚ ä¸€ç¯‡ç¤¾åŒºå¸–å­æŠ¥å‘Šäº†åœ¨ä½¿ç”¨ Gradio space ä¸­çš„ `torch.load()` æ—¶é‡åˆ°çš„é”™è¯¯ï¼š`_pickle.UnpicklingError: invalid load key, 'v'`ã€‚ ç”¨æˆ·å°è¯•åŠ è½½æ¨¡å‹æ—¶ï¼Œåœ¨ååºåˆ—åŒ–æ—¶æ”¶åˆ°äº†é”™è¯¯ã€‚ è¯¥ space æ¶‰åŠç”¨äºè‡ªå®šä¹‰è¯­éŸ³çš„ KokoroTTSï¼Œç”¨æˆ·æ­£åœ¨è¯¢é—®æ­£ç¡®çš„ `torch` ç‰ˆæœ¬ã€‚è¿˜æåˆ°äº†ä¸Šä¼ å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘çš„åŠŸèƒ½ï¼Œä»¥åŠæ³¨å†Œæˆ–ç™»å½•ä»¥å‘è¡¨è¯„è®ºçš„æç¤ºã€‚ é”™è¯¯å †æ ˆè·Ÿè¸ªåŒ…å«ï¼š`torch.serialization.py`ï¼Œ`_pickle.UnpicklingError`ï¼Œ`torch.load(path, map_location='cuda', weights_only=False)['net'].items()`ã€‚

---

## [Cohere on Hugging Face Inference Providers ğŸ”¥](https://huggingface.co/blog/inference-providers-cohere) ï¼ˆ2025-04-16ï¼‰

## Summary (æ‘˜è¦)

**English:**

This article announces that Cohere is now a supported Inference Provider on the Hugging Face Hub. Cohere is committed to providing secure AI solutions for enterprise use-cases, including Generative AI, Embeddings, and Ranking models. Cohere Labs supports fundamental research. Several Cohere models are now available for serverless inference, including:

*   `CohereLabs/c4ai-command-r-v01`
*   `CohereLabs/c4ai-command-r-plus`
*   `CohereLabs/c4ai-command-r-08-2024`
*   `CohereLabs/c4ai-command-r7b-12-2024`
*   `CohereLabs/c4ai-command-a-03-2025`
*   `CohereLabs/aya-expanse-8b`
*   `CohereLabs/aya-expanse-32b`
*   `CohereLabs/aya-vision-8b`
*   `CohereLabs/aya-vision-32b`

Specifically, `CohereLabs/c4ai-command-a-03-2025` is highlighted for its suitability for enterprises requiring fast, secure, and high-quality AI, featuring a 256k context length.

**ä¸­æ–‡:**

è¿™ç¯‡æ–‡ç« å®£å¸ƒ Cohere ç°åœ¨æ˜¯ Hugging Face Hub ä¸Šæ”¯æŒçš„ Inference Provider (æ¨ç†æä¾›å•†)ã€‚Cohere è‡´åŠ›äºä¸ºä¼ä¸šç”¨ä¾‹æä¾›å®‰å…¨çš„ AI è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ Generative AI (ç”Ÿæˆå¼AI)ã€Embeddings (åµŒå…¥) å’Œ Ranking (æ’åº) æ¨¡å‹ã€‚ Cohere Labs æ”¯æŒåŸºç¡€ç ”ç©¶ã€‚ç°åœ¨å¯ä»¥é€šè¿‡ Cohere å’Œ Inference Providers è¿›è¡Œä»¥ä¸‹ Cohere æ¨¡å‹çš„ Serverless Inference (æ— æœåŠ¡å™¨æ¨ç†)ï¼š

*   `CohereLabs/c4ai-command-r-v01`
*   `CohereLabs/c4ai-command-r-plus`
*   `CohereLabs/c4ai-command-r-08-2024`
*   `CohereLabs/c4ai-command-r7b-12-2024`
*   `CohereLabs/c4ai-command-a-03-2025`
*   `CohereLabs/aya-expanse-8b`
*   `CohereLabs/aya-expanse-32b`
*   `CohereLabs/aya-vision-8b`
*   `CohereLabs/aya-vision-32b`

ç‰¹åˆ«æåˆ° `CohereLabs/c4ai-command-a-03-2025`ï¼Œå®ƒé€‚ç”¨äºéœ€è¦å¿«é€Ÿã€å®‰å…¨å’Œé«˜è´¨é‡ AI çš„ä¼ä¸šï¼Œå¹¶å…·æœ‰ 256k context length (ä¸Šä¸‹æ–‡é•¿åº¦)ã€‚

## Summary in English and Chinese:

**English:**

This text highlights Cohere's advanced Language Model offerings, emphasizing their multilingual capabilities and advanced features.  Key models mentioned include:

*   **aya-expanse-32b:**  Focuses on state-of-the-art multilingual support (23 languages), leveraging recent research in multilingual pre-training. Features a 128K context length.
*   **c4ai-command-r7b-12-2024:**  Ideal for low-cost/low-latency use cases.  Offers 128K context length, multilingual support (23 languages), citation-verified **Retrieval-Augmented Generation (RAG)**, reasoning, tool use, and agentic behavior. An open-weight model with strong performance.
*   **aya-vision-32b:**  A 32-billion parameter vision-language model optimized for tasks such as **OCR**, captioning, visual reasoning, summarization, question answering, and code. Supports 23 languages.

The text also describes how to use Cohere models on the Hugging Face Hub via the website UI and client SDKs (specifically Python with `huggingface_hub`).  It provides links to the Cohere documentation page and a Colab notebook for examples.

**Chinese:**

è¯¥æ–‡æœ¬é‡ç‚¹ä»‹ç»äº†Cohereå…ˆè¿›çš„è¯­è¨€æ¨¡å‹äº§å“ï¼Œå¼ºè°ƒå…¶å¤šè¯­è¨€èƒ½åŠ›å’Œé«˜çº§åŠŸèƒ½ã€‚æåˆ°çš„å…³é”®æ¨¡å‹åŒ…æ‹¬ï¼š

*   **aya-expanse-32b:** ä¸“æ³¨äºæœ€å…ˆè¿›çš„å¤šè¯­è¨€æ”¯æŒï¼ˆ23ç§è¯­è¨€ï¼‰ï¼Œåˆ©ç”¨å¤šè¯­è¨€é¢„è®­ç»ƒçš„æœ€æ–°ç ”ç©¶ã€‚å…·æœ‰128Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚
*   **c4ai-command-r7b-12-2024:**  é€‚ç”¨äºä½æˆæœ¬/ä½å»¶è¿Ÿç”¨ä¾‹ã€‚æä¾› 128K çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¤šè¯­è¨€æ”¯æŒï¼ˆ23 ç§è¯­è¨€ï¼‰ï¼Œå¼•ç”¨éªŒè¯çš„**æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)**ï¼Œæ¨ç†ï¼Œå·¥å…·ä½¿ç”¨å’Œ Agentic è¡Œä¸ºã€‚ä¸€ä¸ªå…·æœ‰å¼ºå¤§æ€§èƒ½çš„å¼€æ”¾æƒé‡æ¨¡å‹ã€‚
*   **aya-vision-32b:** ä¸€ä¸ª320äº¿å‚æ•°çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé’ˆå¯¹è¯¸å¦‚ **OCR**ã€å­—å¹•ã€è§†è§‰æ¨ç†ã€æ‘˜è¦ã€é—®ç­”å’Œä»£ç ç­‰ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ”¯æŒ23ç§è¯­è¨€ã€‚

è¯¥æ–‡æœ¬è¿˜æè¿°äº†å¦‚ä½•åœ¨ Hugging Face Hub ä¸Šé€šè¿‡ç½‘ç«™ UI å’Œå®¢æˆ·ç«¯ SDKï¼ˆç‰¹åˆ«æ˜¯ä½¿ç”¨ `huggingface_hub` çš„ Pythonï¼‰ä½¿ç”¨ Cohere æ¨¡å‹ã€‚ å®ƒæä¾›äº†æŒ‡å‘ Cohere æ–‡æ¡£é¡µé¢å’Œ Colab notebook çš„é“¾æ¥ï¼Œä»¥ä¾›å‚è€ƒç¤ºä¾‹ã€‚

## Summary (æ‘˜è¦):

This document describes how to use Cohere as an inference provider via the Hugging Face Hub. It details the necessary setup, including installing `huggingface_hub>=0.30.0` and using the `InferenceClient` with the `provider="cohere"` parameter and your Cohere API key.

**Key points:**

*   **Setup:** Install `huggingface_hub>=0.30.0`.
*   **`InferenceClient`:** Instantiate with `provider="cohere"` and your API key:

    ```python
    from huggingface_hub import InferenceClient

    client = InferenceClient(
        provider="cohere",
        api_key="xxxxxxxxxxxxxxxxxxxxxxxx",
    )
    ```

*   **Chat Completion:** Use `client.chat.completions.create()` to generate responses.  Example usage with `CohereLabs/c4ai-command-r7b-12-2024`:

    ```python
    completion = client.chat.completions.create(
        model="CohereLabs/c4ai-command-r7b-12-2024",
        messages=messages,
        temperature=0.7,
        max_tokens=512,
    )
    ```

*   **Multimodal Support (Aya Vision):** Shows how to send base64 encoded images to Cohere's Aya Vision model:

    ```python
    image_path = "img.jpg"
    with open(image_path, "rb") as f:
        base64_image = base64.b64encode(f.read()).decode("utf-8")
    image_url = f"data:image/jpeg;base64,{base64_image}"

    messages = [
            {
    "role": "user",
    "content": [
                    {"type": "text", "text": "What's in this image?"},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ]
            }
    ]

    completion = client.chat.completions.create(
        model="CohereLabs/aya-vision-32b",
        messages=messages,
        temperature=0.7,
        max_tokens=512,
    )
    ```
*   **JavaScript Example:** Demonstrates using `@huggingface/inference` to call Cohere chat completion endpoints from JavaScript.
```javascript
import { HfInference } from "@huggingface/inference";
const client = new HfInference("xxxxxxxxxxxxxxxxxxxxxxxx");
const chatCompletion = await client.chatCompletion({
    model: "CohereLabs/c4ai-command-a-03-2025",
    messages: [{ role: "user", content: "How to mak"}],
});
```

---

## ä¸­æ–‡æ‘˜è¦:

æœ¬æ–‡æ¡£æè¿°äº†å¦‚ä½•é€šè¿‡ Hugging Face Hub å°† Cohere ç”¨ä½œæ¨ç†æä¾›å•†ã€‚ å®ƒè¯¦ç»†ä»‹ç»äº†å¿…è¦çš„è®¾ç½®ï¼ŒåŒ…æ‹¬å®‰è£… `huggingface_hub>=0.30.0` å’Œä½¿ç”¨å¸¦æœ‰ `provider="cohere"` å‚æ•°å’Œæ‚¨çš„ Cohere API å¯†é’¥çš„ `InferenceClient`ã€‚

**å…³é”®ç‚¹ï¼š**

*   **è®¾ç½®ï¼š** å®‰è£… `huggingface_hub>=0.30.0`ã€‚
*   **`InferenceClient`ï¼š** ä½¿ç”¨ `provider="cohere"` å’Œæ‚¨çš„ API å¯†é’¥è¿›è¡Œå®ä¾‹åŒ–ï¼š

    ```python
    from huggingface_hub import InferenceClient

    client = InferenceClient(
        provider="cohere",
        api_key="xxxxxxxxxxxxxxxxxxxxxxxx",
    )
    ```

*   **èŠå¤©è¡¥å…¨ï¼š** ä½¿ç”¨ `client.chat.completions.create()` ç”Ÿæˆå“åº”ã€‚ ä½¿ç”¨ `CohereLabs/c4ai-command-r7b-12-2024` çš„ç¤ºä¾‹ç”¨æ³•ï¼š

    ```python
    completion = client.chat.completions.create(
        model="CohereLabs/c4ai-command-r7b-12-2024",
        messages=messages,
        temperature=0.7,
        max_tokens=512,
    )
    ```

*   **å¤šæ¨¡æ€æ”¯æŒ (Aya Vision):** å±•ç¤ºäº†å¦‚ä½•å°† base64 ç¼–ç çš„å›¾åƒå‘é€åˆ° Cohere çš„ Aya Vision æ¨¡å‹ï¼š

    ```python
    image_path = "img.jpg"
    with open(image_path, "rb") as f:
        base64_image = base64.b64encode(f.read()).decode("utf-8")
    image_url = f"data:image/jpeg;base64,{base64_image}"

    messages = [
            {
    "role": "user",
    "content": [
                    {"type": "text", "text": "What's in this image?"},
                    {"type": "image_url", "image_url": {"url": image_url}},
                ]
            }
    ]

    completion = client.chat.completions.create(
        model="CohereLabs/aya-vision-32b",
        messages=messages,
        temperature=0.7,
        max_tokens=512,
    )
    ```

*  **JavaScript ç¤ºä¾‹ï¼š**æ¼”ç¤ºäº†ä½¿ç”¨ `@huggingface/inference` ä» JavaScript è°ƒç”¨ Cohere èŠå¤©è¡¥å…¨ç«¯ç‚¹ã€‚
```javascript
import { HfInference } from "@huggingface/inference";
const client = new HfInference("xxxxxxxxxxxxxxxxxxxxxxxx");
const chatCompletion = await client.chatCompletion({
    model: "CohereLabs/c4ai-command-a-03-2025",
    messages: [{ role: "user", content: "How to mak"}],
});
```

## æ‘˜è¦ (Summary)

**ä¸­æ–‡:**

æœ¬æ–‡å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ OpenAI å®¢æˆ·ç«¯åº“ï¼Œä½¿ç”¨ Cohere ä½œä¸ºæ¨ç†æä¾›è€…æ¥è°ƒç”¨ Command R7B æ¨¡å‹ã€‚æ–‡ç« æä¾›äº†ä½¿ç”¨ `OpenAI` å®¢æˆ·ç«¯è¿›è¡ŒèŠå¤©è¡¥å…¨çš„ä»£ç ç¤ºä¾‹ï¼ŒåŒ…æ‹¬è®¾ç½® `base_url` å’Œ `api_key`ï¼Œä»¥åŠä¼ é€’åŒ…å«ç”¨æˆ·æ¶ˆæ¯ `messages` çš„åˆ—è¡¨ã€‚è¿˜ä»‹ç»äº† Cohere æ¨¡å‹çš„å·¥å…·ä½¿ç”¨åŠŸèƒ½ (Tool Use)ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•å®šä¹‰å·¥å…·ï¼ˆä¾‹å¦‚ `get_flight_info`ï¼Œç”¨äºè·å–ä¸¤åœ°ä¹‹é—´çš„èˆªç­ä¿¡æ¯ï¼‰ä»¥åŠå¦‚ä½•åœ¨ `tool_calls` ä¸­ä¼ é€’æ¶ˆæ¯ç»™æ¨ç†å®¢æˆ·ç«¯ï¼Œä»¥ä¾¿æ¨¡å‹åœ¨éœ€è¦æ—¶ä½¿ç”¨è¿™äº›å·¥å…·ã€‚ å·¥å…·çš„å®šä¹‰åŒ…æ‹¬ `type`ï¼Œ`function` å’Œ `parameters`ï¼Œå…¶ä¸­å‚æ•°åŒ…æ‹¬ `loc_origin` å’Œ `loc_destination`ï¼Œç”¨äºæŒ‡å®šèµ·é£åœ°å’Œç›®çš„åœ°æœºåœºã€‚

**English:**

This document demonstrates how to call the Command R7B model using Cohere as the inference provider via the OpenAI client library. It provides a code example of using the `OpenAI` client for chat completions, including setting the `base_url` and `api_key`, and passing a list of `messages` containing the user's message. It also introduces the Tool Use feature of Cohere models and shows how to define tools (e.g., `get_flight_info`, which retrieves flight information between two locations) and how to pass messages with `tool_calls` to the inference client so that the model can use these tools when relevant. The tool definition includes `type`, `function`, and `parameters`, where the parameters include `loc_origin` and `loc_destination` for specifying the departure and destination airports.

å¥½çš„ï¼Œè¿™æ˜¯å¯¹ä½ æä¾›çš„å†…å®¹çš„æ‘˜è¦ï¼ŒåŒ…å«ä¸­è‹±åŒè¯­ï¼Œå¹¶ä¿ç•™äº†å…¬å¼ä¸æœ¯è¯­ï¼š

**æ‘˜è¦ï¼š**

This text demonstrates how to use the `huggingface_hub` library and `InferenceClient` to interact with a large language model (LLM) from Cohere. It provides a code snippet that uses the `client.chat.completions.create` method to generate a response based on a series of messages and tools. The example shows a multi-turn conversation where a user asks about flight information, the assistant uses a tool (a function call with `name` "get_flight_info" and `arguments` `'{ "loc_destination": "Seattle", "loc_origin": "Miami" }'`) to retrieve the information, and the tool returns the flight details.  The code sets parameters like `model` ("CohereLabs/c4ai-command-r7b-12-2024"), `messages`, `tools`, `temperature` (0.7), and `max_tokens` (512). The document also outlines billing information for both direct requests (using a Cohere key) and routed requests (authenticating via the Hugging Face Hub).  PRO users get $2 worth of Inference credits per month.

**ä¸­æ–‡æ‘˜è¦ï¼š**

è¿™æ®µæ–‡å­—å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `huggingface_hub` åº“å’Œ `InferenceClient` æ¥ä¸ Cohere çš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) äº¤äº’ã€‚å®ƒæä¾›äº†ä¸€æ®µä»£ç ï¼Œä½¿ç”¨ `client.chat.completions.create` æ–¹æ³•åŸºäºä¸€ç³»åˆ—çš„æ¶ˆæ¯å’Œå·¥å…·æ¥ç”Ÿæˆå›å¤ã€‚ç¤ºä¾‹å±•ç¤ºäº†ä¸€ä¸ªå¤šè½®å¯¹è¯ï¼Œå…¶ä¸­ç”¨æˆ·è¯¢é—®èˆªç­ä¿¡æ¯ï¼ŒåŠ©æ‰‹ä½¿ç”¨ä¸€ä¸ªå·¥å…·ï¼ˆä¸€ä¸ªå‡½æ•°è°ƒç”¨ï¼Œ `name` ä¸º "get_flight_info"ï¼Œ `arguments` ä¸º `'{ "loc_destination": "Seattle", "loc_origin": "Miami" }'`ï¼‰æ¥æ£€ç´¢ä¿¡æ¯ï¼Œç„¶åå·¥å…·è¿”å›èˆªç­è¯¦æƒ…ã€‚ä»£ç è®¾ç½®äº†è¯¸å¦‚ `model` ("CohereLabs/c4ai-command-r7b-12-2024")ã€`messages`ã€`tools`ã€`temperature` (0.7) å’Œ `max_tokens` (512) ç­‰å‚æ•°ã€‚è¯¥æ–‡æ¡£è¿˜æ¦‚è¿°äº†ç›´æ¥è¯·æ±‚ï¼ˆä½¿ç”¨ Cohere å¯†é’¥ï¼‰å’Œè·¯ç”±è¯·æ±‚ï¼ˆé€šè¿‡ Hugging Face Hub éªŒè¯ï¼‰çš„è®¡è´¹ä¿¡æ¯ã€‚PRO ç”¨æˆ·æ¯æœˆå¯è·å¾—ä»·å€¼ 2 ç¾å…ƒçš„æ¨ç†ç§¯åˆ†ã€‚

å…³é”®æœ¯è¯­ï¼š`huggingface_hub`, `InferenceClient`, `client.chat.completions.create`, `messages`, `tools`, `temperature`, `max_tokens`, `model`, `function call`, `name`, `arguments`.

**æ‘˜è¦ (Summary):**

The user "borgr" inquired about the possibility of exporting or retrieving user conversations from the UI or via API, potentially for purposes such as data labeling, studying user needs ("what people lack"), and understanding human reactions to Large Language Model (LM) behavior. The article author, "merve," responded that such an option is not currently available but will be considered. They suggested using the providers programmatically and storing the data independently in the meantime.

**è‹±æ–‡æ‘˜è¦ (English Summary):**

The user "borgr" asked if there was a way to export user conversations from the UI or retrieve them via an API request. Their use cases included data labeling, studying user needs ("what people lack"), and understanding human reactions to Large Language Model (LM) behavior. The article author, "merve," replied that this functionality is not yet available but will be considered. They suggested using the providers programmatically and storing the data independently for now.

---

## [Introducing HELMET](https://huggingface.co/blog/helmet) ï¼ˆ2025-04-16ï¼‰



---

